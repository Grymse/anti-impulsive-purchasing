{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comment', 'submission', 'subreddit']\n"
     ]
    }
   ],
   "source": [
    "LOCATION = 'data'\n",
    "USE_FILENAMES = [\"1727069599\", \"1727016938\", \"1727020308\", \"1727024177\", \"1727160042\"]\n",
    "FOLDERS = [\"comment\", \"submission\", \"subreddit\"]\n",
    "\n",
    "# get all folder names\n",
    "print(FOLDERS)\n",
    "\n",
    "# load all data into respective dataframes\n",
    "dfs = {}\n",
    "for folder in FOLDERS:\n",
    "    dfs[folder] = {}\n",
    "    for filename in USE_FILENAMES:\n",
    "        dfs[folder][filename] = pd.read_csv(f\"{LOCATION}/{folder}/{filename}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment/1727069599: 429916\n",
      "comment/1727016938: 57102\n",
      "comment/1727020308: 46451\n",
      "comment/1727024177: 15695\n",
      "comment/1727160042: 191511\n",
      "submission/1727069599: 941\n",
      "submission/1727016938: 100\n",
      "submission/1727020308: 100\n",
      "submission/1727024177: 100\n",
      "submission/1727160042: 880\n",
      "subreddit/1727069599: 1\n",
      "subreddit/1727016938: 1\n",
      "subreddit/1727020308: 1\n",
      "subreddit/1727024177: 1\n",
      "subreddit/1727160042: 1\n"
     ]
    }
   ],
   "source": [
    "# count the number of rows in each dataframe\n",
    "for folder in FOLDERS:\n",
    "    for filename in USE_FILENAMES:\n",
    "        print(f\"{folder}/{filename}: {len(dfs[folder][filename])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment: 740675\n",
      "submission: 2121\n",
      "subreddit: 5\n"
     ]
    }
   ],
   "source": [
    "# for each folder, combine all dataframes into one\n",
    "for folder in FOLDERS:\n",
    "    dfs[folder] = pd.concat(dfs[folder].values())\n",
    "\n",
    "# count the number of rows in each dataframe\n",
    "for folder in FOLDERS:\n",
    "    print(f\"{folder}: {len(dfs[folder])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_bodies = dfs[\"comment\"][\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to a list of strings\n",
    "comment_bodies = comment_bodies.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of words\n",
    "words = [comment.split(\" \") for comment in comment_bodies]\n",
    "word_count = sum([len(comment) for comment in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count: 23666731\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word count: {word_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adamlass/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count (no stopwords): 13141559\n"
     ]
    }
   ],
   "source": [
    "# use nltk to remove stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# remove stopwords\n",
    "words = [[word for word in comment if word.lower() not in stop_words] for comment in words]\n",
    "word_count = sum([len(comment) for comment in words])\n",
    "print(f\"Word count (no stopwords): {word_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df with top 100 words and their respective counts\n",
    "word_count_dict = {}\n",
    "for comment in words:\n",
    "    for word in comment:\n",
    "        if word in word_count_dict:\n",
    "            word_count_dict[word] += 1\n",
    "        else:\n",
    "            word_count_dict[word] = 1\n",
    "items = word_count_dict.items()\n",
    "switched_items = [(count, word) for word, count in items]\n",
    "word_df = pd.DataFrame(switched_items, columns=[\"weight\", \"word\"])\n",
    "word_df = word_df.sort_values(\"weight\", ascending=False)\n",
    "word_df = word_df.head(1000)\n",
    "\n",
    "# save to csv\n",
    "word_df.to_csv(\"word_count.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submissions with URLs: 2118\n"
     ]
    }
   ],
   "source": [
    "# get submissions\n",
    "submissions = dfs[\"submission\"]\n",
    "\n",
    "# count how many submissions have a url\n",
    "urls = submissions[\"url\"]\n",
    "urls = urls.astype(str)\n",
    "urls = urls.str.contains(\"http\")\n",
    "urls = urls.sum()\n",
    "print(f\"Submissions with URLs: {urls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2121\n",
      "Percentage with URLs:  0.9985855728429985\n"
     ]
    }
   ],
   "source": [
    "print(len(submissions))\n",
    "print(\"Percentage with URLs: \", urls / len(submissions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
