{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import TTestIndPower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252.12750515434067"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "powertest = TTestIndPower()\n",
    "\n",
    "percentage_effect = -0.2\n",
    "mean_before = 5\n",
    "mean_after = mean_before * (1 + percentage_effect)\n",
    "std = 4\n",
    "\n",
    "effect_size = (mean_after - mean_before) / std\n",
    "\n",
    "powertest.solve_power(effect_size=effect_size, power=0.8, nobs1=None, ratio=1, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interview:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' for diff in mean_difference:\\n    # Create a t-test power analysis for each interview mean difference\\n    effect_size = diff+interview_mean / interview_std\\n    size = powertest.solve_power(effect_size=effect_size, power=0.8, nobs1=None, ratio=1, alpha=0.05)\\n    print(f\"Mean difference: {diff}, Power: {size}\") '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "interview_mean = 2.0125\n",
    "interview_std = 2.9811\n",
    "\n",
    "questionary_mean = 2.7285\n",
    "questionary_std = 6.9595\n",
    "\n",
    "mean_difference = [-1.5, -1, -.5, 0, .5, 1, 1.5]\n",
    "percentage_effect = [-0.1, -0.2, -0.3, -0.4, -0.5]\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = pd.DataFrame(index=mean_difference, columns=percentage_effect)\n",
    "\n",
    "for diff in mean_difference:\n",
    "    for perc in percentage_effect:\n",
    "        std = interview_std\n",
    "        mean_before = interview_mean + diff\n",
    "        mean_after = mean_before * (1 + perc)\n",
    "        effect_size = (mean_after - mean_before) / std\n",
    "        size = powertest.solve_power(effect_size=effect_size, power=0.8, nobs1=None, ratio=1, alpha=0.05)\n",
    "        results.at[diff, perc] = size\n",
    "\n",
    "results.to_csv('interview_results.csv')\n",
    "\n",
    "\n",
    "print(\"interview:\")\n",
    "\"\"\" for diff in mean_difference:\n",
    "    # Create a t-test power analysis for each interview mean difference\n",
    "    effect_size = diff+interview_mean / interview_std\n",
    "    size = powertest.solve_power(effect_size=effect_size, power=0.8, nobs1=None, ratio=1, alpha=0.05)\n",
    "    print(f\"Mean difference: {diff}, Power: {size}\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1434765124355035 7.215486009835625e-05\n",
      "[ 8.77131645e+00  4.70540865e+00  6.43021580e+00  1.01928267e+01\n",
      "  9.07987712e+00  5.99136912e-01  6.34480858e+00  3.06128903e+00\n",
      "  3.20479428e+00  4.73653519e+00  3.94190829e+00  7.84783475e+00\n",
      "  5.78122956e+00  3.87522539e+00  4.83570068e+00  4.50721654e+00\n",
      "  7.96649912e+00  2.90090270e+00  4.44578613e+00  9.66355192e-01\n",
      " -4.09821794e+00  5.46100239e+00  6.08947075e+00  1.30003186e+00\n",
      "  1.02788655e+01 -8.23109513e-01  3.64891072e+00  2.95448622e+00\n",
      "  8.08186812e+00  7.89280543e+00  3.97441377e+00  4.63984029e+00\n",
      "  8.65921908e-01 -2.39245235e+00  2.47533909e+00  3.97859191e+00\n",
      "  7.18011955e+00  7.09691457e+00  2.35784002e+00  2.61130527e+00\n",
      "  3.86658756e-01 -7.20715473e-01 -1.57406207e+00  9.32795653e+00\n",
      "  1.99317588e+00  2.20655670e+00 -2.22208248e-01  5.83027650e+00\n",
      " -1.29869087e+00  2.87829995e+00  8.43024634e-01  4.66589504e+00\n",
      "  1.98973880e+00 -7.08260409e-03  3.42848596e+00  4.78940014e+00\n",
      "  3.71079449e+00  4.41419897e+00  1.62152241e+00  2.43113231e+00\n",
      "  1.50782816e+00  2.44063607e+00  1.08842962e+00 -1.63372107e+00\n",
      "  4.04142507e+00  2.31475085e+00 -1.34728429e+00  4.89210018e+00\n",
      "  8.07752846e-01  3.66735442e+00  5.68599187e+00  3.89701096e+00\n",
      "  6.90916738e+00 -1.68639253e-01  4.71192067e+00  1.47101264e+00\n",
      "  9.16566619e-01  1.78689126e+00  2.58373075e+00  3.67993450e+00\n",
      "  3.90718096e-02  6.19795384e+00  4.90068630e+00 -1.06719605e+00\n",
      "  7.94912861e+00  9.16433522e+00  7.02655978e+00  2.97612607e+00\n",
      "  3.20479360e-01  6.65592604e+00  2.31058920e+00  7.15673100e+00\n",
      "  4.13338854e+00  6.42395863e+00  4.57486387e+00  5.61886527e+00\n",
      "  3.54380161e+00  8.83635853e+00  3.89083764e+00  4.71087049e+00]\n"
     ]
    }
   ],
   "source": [
    "# Try generating a dataset with the calculated sample size\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "np.random.seed(0)\n",
    "n = 100\n",
    "before = np.random.normal(loc=mean_before, scale=std, size=n)\n",
    "after = np.random.normal(loc=mean_after, scale=std, size=n)\n",
    "\n",
    "t, p = stats.ttest_rel(before, after)\n",
    "print(t, p)\n",
    "\n",
    "# Print out before\n",
    "print(before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
